{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZ8_rATdS42e"
   },
   "source": [
    "<img src=\"https://futurejobs.my/wp-content/uploads/2021/05/d-min-1024x297.png\" width=\"300\"> </img>\n",
    "\n",
    "> **Copyright &copy; 2021 Skymind Education Group Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program and the accompanying materials are made available under the\n",
    "terms of the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \\\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License. <br>\n",
    "<br>**SPDX-License-Identifier: Apache-2.0** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85zQOHOkUAtN"
   },
   "source": [
    "# Convolutional Neural Network: MNIST Image Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4M1ZnIUSa3i"
   },
   "source": [
    "## Objectives\n",
    "In this hands-on, we will :-\n",
    "\n",
    "1. Load MNIST dataset from `torchvision` library.\n",
    "2. Make the dataset iterable by using it as a DataLoader object.\n",
    "3. Understand the data flow in a CNN model.\n",
    "4. Build a custom Convolutional Neural Network (CNN) model class.\n",
    "5. Instantiate the Model class.\n",
    "6. Instantiate the Loss class.\n",
    "7. Instantiate the Optimizer class.\n",
    "8. Train the CNN Model.\n",
    "9. Visualize metrics of the CNN Model.\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o-u4zD1iKy4"
   },
   "source": [
    "### Importing the necessary libraries for this hands-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQQZ00gSqp2x"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader #to create DataLoader objects\n",
    "from torch import nn #to work with trainable neural networks\n",
    "from torch.nn import functional as F #to access activation functions, pooling, dropout etc\n",
    "from torch import optim #to access PyTorch optimizers\n",
    "\n",
    "from torchvision import datasets #to access PyTorch datasets\n",
    "from torchvision import transforms #to access the methods and classes to do Tensor Transformations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJWrFdQppUM5"
   },
   "source": [
    "### Basic initialization steps in PyTorch framework\n",
    "\n",
    "To ensure the reproducibility of the outcome of a code, it is vital to set the `seed` for anything that introduces randomized numbers such as random number generators from the `random` library. So instead of being completely random, we introduce a level of control to the element of randomness. This is what we call as **pseudo-random**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKmttGJVpYSZ"
   },
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r49-CfYNifcT"
   },
   "source": [
    "## Load MNIST dataset from `torchvision` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8KC2l0hZlGu"
   },
   "outputs": [],
   "source": [
    "# load the MNIST dataset from the `datasets` package\n",
    "train_dataset = datasets.MNIST(root=\"../datasets\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root=\"../datasets\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icyB6HvdhdHA"
   },
   "outputs": [],
   "source": [
    "# Description of the train dataset\n",
    "print(\"Data size: \", train_dataset.data.size())\n",
    "print(\"Label size: \", train_dataset.targets.size(), \"\\n\")\n",
    "\n",
    "print(\"--Default Description--\\n\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoQAAAfRs16N"
   },
   "source": [
    "The description above shows that the training set has 60,000 datapoints with each tensor having a size of `28 x 28 x 1`. The size of the targets also match the total datapoints. \n",
    "\n",
    "This is no coincidence as the datasets available within `PyTorch` and most other Deep Learning frameworks have already been wrangled and cleaned for learners like yourself to accustom to using the frameworks and concepts quickly. It may not be the case when one is working on a realworld dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_h_njJXhpT3"
   },
   "outputs": [],
   "source": [
    "# Description of the test dataset\n",
    "print(\"Data size: \", test_dataset.data.size())\n",
    "print(\"Label size: \", test_dataset.targets.size(), \"\\n\")\n",
    "\n",
    "print(\"--Default Description--\\n\")\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vctKyfcqkSFe"
   },
   "source": [
    "Similarly, the test set has 10,000 datapoints. We may infer that the images are either black and white or grayscaled since there is only one channel (An RGB equivalent would have the size of `28 x 28 x 3`).\n",
    "\n",
    "To confirm any assumptions and to get more information, checkout the details of [MNIST dataset here](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3_15lOCPYr4"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. Make the dataset iterable by using it as a DataLoader object.\n",
    "3. Understand the data flow in a CNN model.\n",
    "4. Build a custom Convolutional Neural Network (CNN) model class.\n",
    "5. Instantiate the Model class.\n",
    "6. Instantiate the Loss class.\n",
    "7. Instantiate the Optimizer class.\n",
    "8. Train the CNN Model.\n",
    "9. Visualize metrics of the CNN Model.\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_rns8fhiahk"
   },
   "source": [
    "## Making the dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jteQDU0oRPf"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"test\": test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXsbtP7-NGIk"
   },
   "source": [
    "Now that we have our DataLoader objects for both the training set and test set, we can begin with first getting a feel of what the data point goes through when in a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVktCiImPnIH"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. ~~Make the dataset iterable by using it as a DataLoader object.~~\n",
    "3. Understand the data flow in a CNN model.\n",
    "4. Build a custom Convolutional Neural Network (CNN) model class.\n",
    "5. Instantiate the Model class.\n",
    "6. Instantiate the Loss class.\n",
    "7. Instantiate the Optimizer class.\n",
    "8. Train the CNN Model.\n",
    "9. Visualize metrics of the CNN Model.\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IS_xErxyPEDM"
   },
   "source": [
    "## Data Flow in a CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp3FuZn7Puti"
   },
   "source": [
    "Let's begin by first creating the objects of two 2D Convolution layers and extracting the first datapoint in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-zNXKSjGJD6"
   },
   "outputs": [],
   "source": [
    "# Convolutional layer\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1)\n",
    "conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1)\n",
    "\n",
    "# Get first datapoint\n",
    "X_train, y_train = train_dataset[0]\n",
    "print(\"Shape of X_train: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_69PNq7Qo3v"
   },
   "source": [
    "Reshape the originally 3-D Tensor into 4-D as the convolution expects input in 4-dimensional weight.\n",
    "\n",
    "_[n_samples, channels, height, width]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69ja8p0fXAai"
   },
   "outputs": [],
   "source": [
    "print(\"Dim before: \", X_train.ndim)\n",
    "print(\"Shape before: \", list(X_train.shape), \"\\n\")\n",
    "\n",
    "X_train_reshaped = X_train.view(-1,1,28,28)\n",
    "\n",
    "print(\"Dim after: \", X_train_reshaped.ndim)\n",
    "print(\"Shape after: \", list(X_train_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAMfHQnHbF9S"
   },
   "source": [
    "Perform the first convolution and notice the shape of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVizxrL2XRQq"
   },
   "outputs": [],
   "source": [
    "out = conv1(X_train_reshaped)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll9SyTLse2oc"
   },
   "source": [
    "Perform the ReLU activation on the previous output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAV1czrRe2Jf"
   },
   "outputs": [],
   "source": [
    "out = F.relu(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkpWieBjfDfN"
   },
   "source": [
    "Perform the first pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnqzWQlsZfMF"
   },
   "outputs": [],
   "source": [
    "out = F.max_pool2d(out, 2, 2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwf6Xz96i3Id"
   },
   "source": [
    "Perform the second convolution, activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auyET84iirMd"
   },
   "outputs": [],
   "source": [
    "out = F.relu(conv2(out))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqZXse8njUUT"
   },
   "source": [
    "Perform the second pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Nt9d_lLjT6t"
   },
   "outputs": [],
   "source": [
    "out = F.max_pool2d(out, 2, 2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z5fUETTxg7J"
   },
   "source": [
    "By now, you should have a picture on how the tensor's shape gets manipulated throughout the layers in a CNN. Next, let's build our own full-fledge, CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4rVI3N5z5vG"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. ~~Make the dataset iterable by using it as a DataLoader object.~~\n",
    "3. ~~Understand the data flow in a CNN model.~~\n",
    "4. Build a custom Convolutional Neural Network (CNN) model class.\n",
    "5. Instantiate the Model class.\n",
    "6. Instantiate the Loss class.\n",
    "7. Instantiate the Optimizer class.\n",
    "8. Train the CNN Model.\n",
    "9. Visualize metrics of the CNN Model.\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy6nlLSPz8Ii"
   },
   "source": [
    "### Build A Custom CNN Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqKhif3C0Hq4"
   },
   "source": [
    "We should determine a few parameters before starting out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAXhP3KCjG9b"
   },
   "outputs": [],
   "source": [
    "# Set up hyperparameter\n",
    "epochs = 10\n",
    "num_input = 1  # 3 for RGB image\n",
    "num_output = 10 # total targets/ classes\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9BayrnS0esP"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNNModel, self).__init__()\n",
    "\n",
    "    # Convolution 1\n",
    "    self.conv1 = nn.Conv2d(in_channels=num_input, out_channels=8, kernel_size=3, stride=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1)\n",
    "    self.fc1 = nn.Linear(in_features=5*5*16, out_features=164)\n",
    "    self.fc2 = nn.Linear(in_features=164, out_features=100)\n",
    "    self.fc3 = nn.Linear(in_features=100, out_features=num_output)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.conv1(x))\n",
    "    out = F.max_pool2d(out, 2, 2)\n",
    "    out = F.relu(self.conv2(out))\n",
    "    out = F.max_pool2d(out, 2, 2)\n",
    "    out = out.view(-1, 5*5*16)\n",
    "    out = F.relu(self.fc1(out))\n",
    "    out = F.relu(self.fc2(out))\n",
    "    out = self.fc3(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzFyX_fXl7rW"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. ~~Make the dataset iterable by using it as a DataLoader object.~~\n",
    "3. ~~Understand the data flow in a CNN model.~~\n",
    "4. ~~Build a custom Convolutional Neural Network (CNN) model class.~~\n",
    "5. Instantiate the Model class.\n",
    "6. Instantiate the Loss class.\n",
    "7. Instantiate the Optimizer class.\n",
    "8. Train the CNN Model.\n",
    "9. Visualize metrics of the CNN Model.\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSu3nT8zl6xa"
   },
   "source": [
    "### Instantiate the Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kqfdju-HYwYX"
   },
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwGBz2nwZRRJ"
   },
   "source": [
    "Know the total number of parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DK5zy4ioZQox"
   },
   "outputs": [],
   "source": [
    "# Calculate total model parameters\n",
    "sum = 0\n",
    "print(\"Total parameter tensors: \",len(list(model.parameters())), \"\\n\")\n",
    "\n",
    "for param in model.parameters():\n",
    "  print(f\"{param.numel():>6} \\t {param.size()}\")\n",
    "  sum = sum + param.numel()\n",
    "print(\"----------------\\n\")\n",
    "print(\"Total parameters: \", sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HwheoPGlILw"
   },
   "source": [
    "There are 10 parameter tensors as there are two tensors for each layer. One for weights and another for bias. \n",
    "\n",
    "By using CNN, the number of parameters are lesser. The training process is faster in CNN than FNN (MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYeGvYrol3dy"
   },
   "source": [
    "## Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4gowpxPlF4t"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hiR7q6gsuaV"
   },
   "source": [
    "## Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1peKbWBvswz-"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD3lpkqv4HY1"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. ~~Make the dataset iterable by using it as a DataLoader object.~~\n",
    "3. ~~Understand the data flow in a CNN model.~~\n",
    "4. ~~Build a custom Convolutional Neural Network (CNN) model class.~~\n",
    "5. ~~Instantiate the Model class.~~\n",
    "6. ~~Instantiate the Loss class.~~\n",
    "7. ~~Instantiate the Optimizer class.~~\n",
    "8. Train the CNN Model.\n",
    "9. Visualize metrics of the CNN Model.\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dmVIx_v4Kam"
   },
   "source": [
    "### Train the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yaa5uHtX4Mxq"
   },
   "source": [
    "Let's instantiate the `SummaryWriter` class to assist in collecting the data required to display the Accuracy and Losses in Tensorboard. More details on `SummaryWriter` [here](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLQp0ftVs7ff"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./run_CNN_MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nh_CglcyzBfy"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()  # Start time\n",
    "\n",
    "# Implement model training and validation loop\n",
    "loss_score = {'train': [], 'test': []}\n",
    "accuracy_score = {'train': [], 'test': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f\"Epoch {epoch}\\n---------\")\n",
    "\n",
    "  for loader in [\"train\", \"test\"]:\n",
    "    running_loss = 0.0\n",
    "    running_size = 0\n",
    "    correct = 0\n",
    "    log_interval = 100\n",
    "\n",
    "    if loader == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for iter, (X, y) in enumerate(dataloaders[loader]):\n",
    "        iter += 1\n",
    "        # Set gradient calculation on for train/ off for test\n",
    "        with torch.set_grad_enabled(loader == 'train'):\n",
    "            output = model(X)  # No need to flatten image here\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            # Calculate loss\n",
    "            running_loss += loss.item() * output.size(0)\n",
    "            running_size += output.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predict = torch.max(output, 1)[1]\n",
    "            correct += (predict == y).sum().item()\n",
    "\n",
    "            if loader == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # Print every 100 iteration\n",
    "                if iter == 1 or (iter % log_interval) == 0:\n",
    "                    print('Iteration:{} Loss:{:.6} Accuracy:{:.6} Batch size:[{}/{}]'.format(\n",
    "                        int(iter),\n",
    "                        running_loss/running_size,\n",
    "                        (100*correct)/running_size,\n",
    "                        running_size,\n",
    "                        len(train_dataset)\n",
    "                    ))\n",
    "\n",
    "    # Accuracy and loss per epoch\n",
    "    accuracy = (100*correct) / running_size\n",
    "    loss_per_epoch = running_loss / running_size\n",
    "\n",
    "    print('\\n{} Loss:{}'.format(loader.capitalize(), loss_per_epoch))\n",
    "    print('{} Accuracy:{}\\n'.format(loader.capitalize(), accuracy))\n",
    "\n",
    "    loss_score[loader].append(loss_per_epoch)\n",
    "    accuracy_score[loader].append(accuracy)\n",
    "\n",
    "    writer.add_scalars('Losses', {loader: loss_per_epoch}, epoch)\n",
    "    writer.add_scalars('Accuracy', {loader: accuracy}, epoch)\n",
    "print('***************\\n')\n",
    "\n",
    "# Print the time elapsed\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aF7-mRAY5Acs"
   },
   "source": [
    "The cell output already displays a lot of information in the form of text. You can also make use of `Tensorboard` to visualize the accuracies and losses per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCPQuLzU0RJL"
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir=run_CNN_MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izB7K88b5pK3"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. ~~Make the dataset iterable by using it as a DataLoader object.~~\n",
    "3. ~~Understand the data flow in a CNN model.~~\n",
    "4. ~~Build a custom Convolutional Neural Network (CNN) model class.~~\n",
    "5. ~~Instantiate the Model class.~~\n",
    "6. ~~Instantiate the Loss class.~~\n",
    "7. ~~Instantiate the Optimizer class.~~\n",
    "8. ~~Train the CNN Model.~~\n",
    "9. ~~Visualize metrics of the CNN Model.~~\n",
    "10. Save and load the CNN Model.\n",
    "11. Classify a test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwc0uGaD5wD4"
   },
   "source": [
    "### Saving and loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQbK0EIc0Uxc"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./CNN_MNIST.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IEpVc_46F49"
   },
   "source": [
    "By doing that, you will save all the learned parameters _{\"bias\":[], \"weight\":[]}_, or in other words the whole state of the model. We can load this back into another CNN Model (with the same architecture) using the following lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FMYrWIt6FmX"
   },
   "outputs": [],
   "source": [
    "new_model = CNNModel()\n",
    "new_model.load_state_dict(torch.load(\"./CNN_MNIST.pt\"))\n",
    "new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og7UQaIG9aMC"
   },
   "source": [
    "You may compare the parametes of both old and new models to verify if you were able to reload the parameters correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gy0IO_eK5-XA"
   },
   "outputs": [],
   "source": [
    "def compareModelWeights(model1, model2):\n",
    "  \"\"\"This function recursively compares the weights of two models.\n",
    "  \n",
    "  Returns\n",
    "  -------\n",
    "  boolean : True if both models are equal, else False.\n",
    "  \"\"\"\n",
    "  for p1, p2 in zip(model.parameters(), new_model.parameters()):\n",
    "      if p1.data.ne(p2.data).sum() > 0:\n",
    "          return False\n",
    "  return True\n",
    "\n",
    "compareModelWeights(model, new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t51uRTBw9p8l"
   },
   "source": [
    "### Classify a Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnN3bljb8pTa"
   },
   "outputs": [],
   "source": [
    "image, label = test_dataset[0]\n",
    "print(f\"Shape: {image.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdP1j5AdEvc-"
   },
   "source": [
    "Visualize the test image of the hand-written number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg44sq1HCJme"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray') # use squeeze to flatten the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTustezdE5o0"
   },
   "source": [
    "Reshape the image into 4-D Tensor before inputting into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BH8-h-xEA_ww"
   },
   "outputs": [],
   "source": [
    "output = new_model(image.view(-1, 1, 28,28))\n",
    "predicted = torch.max(output,1)[1].item() # extract indice of the maximum probability\n",
    "print(\"Predicted: \", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0vB3kZuJCLp"
   },
   "source": [
    "**Progress**\n",
    "1. ~~Load MNIST dataset from `torchvision` library.~~\n",
    "2. ~~Make the dataset iterable by using it as a DataLoader object.~~\n",
    "3. ~~Understand the data flow in a CNN model.~~\n",
    "4. ~~Build a custom Convolutional Neural Network (CNN) model class.~~\n",
    "5. ~~Instantiate the Model class.~~\n",
    "6. ~~Instantiate the Loss class.~~\n",
    "7. ~~Instantiate the Optimizer class.~~\n",
    "8. ~~Train the CNN Model.~~\n",
    "9. ~~Visualize metrics of the CNN Model.~~\n",
    "10. ~~Save and load the CNN Model.~~\n",
    "11. ~~Classify a test image.~~\n",
    "\n",
    "## **Congratulations on completing this hands-on! Hope you had fun learning!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+CbKR9RaQqIcMB/wRlfoX",
   "collapsed_sections": [],
   "name": "02_CNN_MNISTClassification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
